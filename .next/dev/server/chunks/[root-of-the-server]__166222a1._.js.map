{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 40, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/aryan/Desktop/New%20folder%20%283%29/PDF-GPT-1/db/index.ts"],"sourcesContent":["import { neon } from '@neondatabase/serverless'\r\nimport { drizzle } from 'drizzle-orm/neon-http'\r\n\r\nconst sql = neon(process.env.DATABASE_URL!)\r\nexport const db = drizzle(sql)"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,MAAM,MAAM,IAAA,yOAAI,EAAC,QAAQ,GAAG,CAAC,YAAY;AAClC,MAAM,KAAK,IAAA,8QAAO,EAAC","debugId":null}},
    {"offset": {"line": 54, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/aryan/Desktop/New%20folder%20%283%29/PDF-GPT-1/db/schema.ts"],"sourcesContent":["import {\r\n  integer,\r\n  pgEnum,\r\n  pgTable,\r\n  serial,\r\n  text,\r\n  timestamp,\r\n  varchar,\r\n  vector,\r\n} from 'drizzle-orm/pg-core'\r\n\r\nexport const userSystemEnum = pgEnum('user_system_enum', ['system', 'user'])\r\n\r\nexport const chats = pgTable('chats', {\r\n  id: serial('id').primaryKey(),\r\n  pdfName: text('pdf_name').notNull(),\r\n  pdfUrl: text('pdf_url').notNull(),\r\n  createdAt: timestamp('created_at').notNull().defaultNow(),\r\n  userId: varchar('user_id', { length: 256 }).notNull(),\r\n  fileKey: text('file_key').notNull(),\r\n})\r\n\r\nexport type DrizzleChat = typeof chats.$inferSelect\r\n\r\nexport const messages = pgTable('messages', {\r\n  id: serial('id').primaryKey(),\r\n  chatId: integer('chat_id')\r\n    .references(() => chats.id)\r\n    .notNull(),\r\n  content: text('content').notNull(),\r\n  createdAt: timestamp('created_at').notNull().defaultNow(),\r\n  role: userSystemEnum('role').notNull(),\r\n})\r\n\r\nexport const documents = pgTable('documents', {\r\n  id: serial('id').primaryKey(),\r\n  chatId: integer('chat_id').notNull()\r\n    .references(() => chats.id),\r\n  content: text('content').notNull(),\r\n  embedding: vector('embedding', { dimensions: 3072 }).notNull(),\r\n})"],"names":[],"mappings":";;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAWO,MAAM,iBAAiB,IAAA,oRAAM,EAAC,oBAAoB;IAAC;IAAU;CAAO;AAEpE,MAAM,QAAQ,IAAA,2QAAO,EAAC,SAAS;IACpC,IAAI,IAAA,sRAAM,EAAC,MAAM,UAAU;IAC3B,SAAS,IAAA,kRAAI,EAAC,YAAY,OAAO;IACjC,QAAQ,IAAA,kRAAI,EAAC,WAAW,OAAO;IAC/B,WAAW,IAAA,4RAAS,EAAC,cAAc,OAAO,GAAG,UAAU;IACvD,QAAQ,IAAA,wRAAO,EAAC,WAAW;QAAE,QAAQ;IAAI,GAAG,OAAO;IACnD,SAAS,IAAA,kRAAI,EAAC,YAAY,OAAO;AACnC;AAIO,MAAM,WAAW,IAAA,2QAAO,EAAC,YAAY;IAC1C,IAAI,IAAA,sRAAM,EAAC,MAAM,UAAU;IAC3B,QAAQ,IAAA,wRAAO,EAAC,WACb,UAAU,CAAC,IAAM,MAAM,EAAE,EACzB,OAAO;IACV,SAAS,IAAA,kRAAI,EAAC,WAAW,OAAO;IAChC,WAAW,IAAA,4RAAS,EAAC,cAAc,OAAO,GAAG,UAAU;IACvD,MAAM,eAAe,QAAQ,OAAO;AACtC;AAEO,MAAM,YAAY,IAAA,2QAAO,EAAC,aAAa;IAC5C,IAAI,IAAA,sRAAM,EAAC,MAAM,UAAU;IAC3B,QAAQ,IAAA,wRAAO,EAAC,WAAW,OAAO,GAC/B,UAAU,CAAC,IAAM,MAAM,EAAE;IAC5B,SAAS,IAAA,kRAAI,EAAC,WAAW,OAAO;IAChC,WAAW,IAAA,0SAAM,EAAC,aAAa;QAAE,YAAY;IAAK,GAAG,OAAO;AAC9D","debugId":null}},
    {"offset": {"line": 220, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/aryan/Desktop/New%20folder%20%283%29/PDF-GPT-1/lib/embeddings.ts"],"sourcesContent":["import { GoogleGenAI } from '@google/genai';\r\n\r\n\r\nconst genAI = new GoogleGenAI({\r\n  apiKey: process.env.GOOGLE_API_KEY!,\r\n});\r\n\r\n\r\nexport async function getEmbeddings(text: string) {\r\n  try {\r\n    const response = await genAI.models.embedContent({\r\n      model: 'gemini-embedding-001',\r\n      contents: text.replace(/\\n/g, ' '),\r\n    })\r\n\r\n    return response.embeddings\r\n  } catch (error) {\r\n    console.log('Error calling Google GenAI', error)\r\n    throw error\r\n  }\r\n}"],"names":[],"mappings":";;;;AAAA;;AAGA,MAAM,QAAQ,IAAI,2OAAW,CAAC;IAC5B,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;AAGO,eAAe,cAAc,IAAY;IAC9C,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,MAAM,CAAC,YAAY,CAAC;YAC/C,OAAO;YACP,UAAU,KAAK,OAAO,CAAC,OAAO;QAChC;QAEA,OAAO,SAAS,UAAU;IAC5B,EAAE,OAAO,OAAO;QACd,QAAQ,GAAG,CAAC,8BAA8B;QAC1C,MAAM;IACR;AACF","debugId":null}},
    {"offset": {"line": 245, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/aryan/Desktop/New%20folder%20%283%29/PDF-GPT-1/lib/context.ts"],"sourcesContent":["import { documents } from '@/db/schema';\r\nimport { getEmbeddings } from './embeddings'\r\nimport { ContentEmbedding } from '@google/genai'\r\nimport { db } from '@/db';\r\nimport { and, asc, eq, gt, sql } from 'drizzle-orm';\r\n\r\nexport async function getContext(query: string, chatId: number) {\r\n  const contentEmbeddings = await getEmbeddings(query)\r\n  if (!contentEmbeddings) throw new Error(\"No query embeddings found\");\r\n\r\n  const matches = await getMatchesFromEmbeddings(contentEmbeddings, chatId)\r\n  console.log(\"matches\", matches);\r\n  return matches.join('\\n').substring(0, 3000)\r\n}\r\n\r\nasync function getMatchesFromEmbeddings(contentEmbeddings: ContentEmbedding[], chatId: number) {\r\n  try {\r\n    const embeddings = contentEmbeddings[0].values;\r\n    if (!embeddings) throw new Error(\"No embeddings found\");\r\n    const vectorString = `[${embeddings.join(',')}]`;\r\n\r\n    let matches = await db\r\n      .select({\r\n        id: documents.id,\r\n        content: documents.content,\r\n        similarity: sql`1 - (documents.embedding <=> ${vectorString}::vector)`.as('similarity'),\r\n      })\r\n      .from(documents).\r\n      where(and(\r\n        eq(documents.chatId, chatId),\r\n        gt(sql`1 - (documents.embedding <=> ${vectorString}::vector)`, 0.7)\r\n      ))\r\n      .orderBy(asc(sql`1 - (documents.embedding <=> ${vectorString}::vector)`))\r\n      .limit(5)\r\n    if (matches.length === 0) {\r\n      matches = await db\r\n        .select({\r\n          id: documents.id,\r\n          content: documents.content,\r\n          similarity: sql`1 - (documents.embedding <=> ${vectorString}::vector)`.as('similarity'),\r\n        })\r\n        .from(documents)\r\n        .where(eq(documents.chatId, chatId))\r\n        .orderBy(sql`1 - (documents.embedding <=> ${vectorString}::vector) DESC`)\r\n        .limit(5);\r\n    }\r\n    return matches.map((match) => match.content)\r\n  } catch (error) {\r\n    console.log('Error querying from embeddings')\r\n    console.log((error as TypeError).stack)\r\n    throw error\r\n  }\r\n}"],"names":[],"mappings":";;;;AAAA;AACA;AAEA;AACA;AAAA;AAAA;;;;;AAEO,eAAe,WAAW,KAAa,EAAE,MAAc;IAC5D,MAAM,oBAAoB,MAAM,IAAA,oIAAa,EAAC;IAC9C,IAAI,CAAC,mBAAmB,MAAM,IAAI,MAAM;IAExC,MAAM,UAAU,MAAM,yBAAyB,mBAAmB;IAClE,QAAQ,GAAG,CAAC,WAAW;IACvB,OAAO,QAAQ,IAAI,CAAC,MAAM,SAAS,CAAC,GAAG;AACzC;AAEA,eAAe,yBAAyB,iBAAqC,EAAE,MAAc;IAC3F,IAAI;QACF,MAAM,aAAa,iBAAiB,CAAC,EAAE,CAAC,MAAM;QAC9C,IAAI,CAAC,YAAY,MAAM,IAAI,MAAM;QACjC,MAAM,eAAe,CAAC,CAAC,EAAE,WAAW,IAAI,CAAC,KAAK,CAAC,CAAC;QAEhD,IAAI,UAAU,MAAM,mHAAE,CACnB,MAAM,CAAC;YACN,IAAI,2HAAS,CAAC,EAAE;YAChB,SAAS,2HAAS,CAAC,OAAO;YAC1B,YAAY,8PAAG,CAAC,6BAA6B,EAAE,aAAa,SAAS,CAAC,CAAC,EAAE,CAAC;QAC5E,GACC,IAAI,CAAC,2HAAS,EACf,KAAK,CAAC,IAAA,oRAAG,EACP,IAAA,mRAAE,EAAC,2HAAS,CAAC,MAAM,EAAE,SACrB,IAAA,mRAAE,EAAC,8PAAG,CAAC,6BAA6B,EAAE,aAAa,SAAS,CAAC,EAAE,OAEhE,OAAO,CAAC,IAAA,gRAAG,EAAC,8PAAG,CAAC,6BAA6B,EAAE,aAAa,SAAS,CAAC,GACtE,KAAK,CAAC;QACT,IAAI,QAAQ,MAAM,KAAK,GAAG;YACxB,UAAU,MAAM,mHAAE,CACf,MAAM,CAAC;gBACN,IAAI,2HAAS,CAAC,EAAE;gBAChB,SAAS,2HAAS,CAAC,OAAO;gBAC1B,YAAY,8PAAG,CAAC,6BAA6B,EAAE,aAAa,SAAS,CAAC,CAAC,EAAE,CAAC;YAC5E,GACC,IAAI,CAAC,2HAAS,EACd,KAAK,CAAC,IAAA,mRAAE,EAAC,2HAAS,CAAC,MAAM,EAAE,SAC3B,OAAO,CAAC,8PAAG,CAAC,6BAA6B,EAAE,aAAa,cAAc,CAAC,EACvE,KAAK,CAAC;QACX;QACA,OAAO,QAAQ,GAAG,CAAC,CAAC,QAAU,MAAM,OAAO;IAC7C,EAAE,OAAO,OAAO;QACd,QAAQ,GAAG,CAAC;QACZ,QAAQ,GAAG,CAAC,AAAC,MAAoB,KAAK;QACtC,MAAM;IACR;AACF","debugId":null}},
    {"offset": {"line": 294, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/aryan/Desktop/New%20folder%20%283%29/PDF-GPT-1/app/api/chat/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server'\r\nimport { StreamingTextResponse, Message } from 'ai'\r\nimport { db } from '@/db'\r\nimport { chats } from '@/db/schema'\r\nimport { eq } from 'drizzle-orm'\r\nimport { getContext } from '@/lib/context'\r\nimport { messages as _messages } from '@/db/schema'\r\nimport { GoogleGenAI } from '@google/genai'\r\n\r\nconst genAI = new GoogleGenAI({\r\n  apiKey: process.env.GOOGLE_API_KEY!,\r\n});\r\n\r\nexport async function POST(request: NextRequest) {\r\n  try {\r\n    const {\r\n      messages,\r\n      chatId,\r\n    }: {\r\n      messages: Message[]\r\n      chatId: number\r\n    } = await request.json()\r\n\r\n    await getFileKeyByChatId(chatId, () => {\r\n      return NextResponse.json({ error: 'Chat not found' })\r\n    })\r\n\r\n    const lastMessage = messages[messages.length - 1]\r\n    console.log(lastMessage);\r\n    const context = await getContext(lastMessage.content, chatId)\r\n    console.log(\"context\", context);\r\n    \r\n    const prompt = `AI assistant is a brand new, powerful, human-like artificial intelligence.\r\nThe traits of AI include expert knowledge, helpfulness, cleverness, and articulateness.\r\nAI is a well-behaved and well-mannered individual.\r\nAI is always friendly, kind, and inspiring, and he is eager to provide vivid and thoughtful responses to the user.\r\nAI has the sum of all knowledge in their brain, and is able to accurately answer nearly any question about any topic in conversation.\r\nSTART CONTEXT BLOCK\r\n${context}\r\nEND OF CONTEXT BLOCK\r\nAI assistant will take into account any CONTEXT BLOCK that is provided in a conversation.\r\nAI assistant will not apologize for previous responses, but instead will indicated new information was gained.\r\nAI assistant will not invent anything that is not drawn directly from the context.\r\n\r\nIMPORTANT: Respond in plain text only.\r\nDo not use Markdown, bullet points, numbering, headings, bold, italics, or special formatting.\r\n`;\r\n\r\n    const conversationHistory = messages\r\n      .map((msg) => `${msg.role}: ${msg.content}`)\r\n      .join('\\n');\r\n\r\n    const fullPrompt = `${prompt}\\n\\nConversation:\\n${conversationHistory}\\n\\nassistant:`;\r\n\r\n    const response = await genAI.models.generateContentStream({\r\n      model: 'gemini-2.0-flash-exp',\r\n      contents: fullPrompt,\r\n    });\r\n\r\n    await db.insert(_messages).values({\r\n      chatId,\r\n      content: lastMessage.content,\r\n      role: 'user',\r\n    })\r\n\r\n    let fullText = \"\";\r\n    \r\n    // Create a readable stream that formats data for AI SDK\r\n    const stream = new ReadableStream({\r\n      async start(controller) {\r\n        const encoder = new TextEncoder();\r\n        try {\r\n          for await (const chunk of response) {\r\n            const text = chunk.text;\r\n            if (text) {\r\n              fullText += text;\r\n              // Format as data stream with newline separator (AI SDK v3 format)\r\n              const formatted = `0:${JSON.stringify(text)}\\n`;\r\n              controller.enqueue(encoder.encode(formatted));\r\n            }\r\n          }\r\n        } catch (err) {\r\n          console.error('Stream error:', err);\r\n          controller.error(err);\r\n        } finally {\r\n          // Save the complete response to database\r\n          if (fullText) {\r\n            await db.insert(_messages).values({\r\n              chatId,\r\n              content: fullText,\r\n              role: 'system',  // Keep as 'system' for database\r\n            });\r\n          }\r\n          controller.close();\r\n        }\r\n      },\r\n    });\r\n\r\n    // Return with proper headers for AI SDK streaming\r\n    return new Response(stream, {\r\n      headers: {\r\n        'Content-Type': 'text/plain; charset=utf-8',\r\n        'X-Vercel-AI-Data-Stream': 'v1',\r\n      },\r\n    });\r\n  } catch (error) {\r\n    console.log(error);\r\n    return NextResponse.json(\r\n      { error: 'Something is going wrong ...' },\r\n      { status: 500 }\r\n    )\r\n  }\r\n}\r\n\r\nasync function getFileKeyByChatId(chatId: number, onError: Function) {\r\n  const _chats = await db.select().from(chats).where(eq(chats.id, chatId))\r\n  if (_chats.length !== 1) onError()\r\n  return _chats[0].fileKey\r\n}"],"names":[],"mappings":";;;;AAAA;AAEA;AACA;AACA;AACA;AAEA;;;;;;;;AAEA,MAAM,QAAQ,IAAI,2OAAW,CAAC;IAC5B,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,EACJ,QAAQ,EACR,MAAM,EACP,GAGG,MAAM,QAAQ,IAAI;QAEtB,MAAM,mBAAmB,QAAQ;YAC/B,OAAO,+PAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAiB;QACrD;QAEA,MAAM,cAAc,QAAQ,CAAC,SAAS,MAAM,GAAG,EAAE;QACjD,QAAQ,GAAG,CAAC;QACZ,MAAM,UAAU,MAAM,IAAA,8HAAU,EAAC,YAAY,OAAO,EAAE;QACtD,QAAQ,GAAG,CAAC,WAAW;QAEvB,MAAM,SAAS,CAAC;;;;;;AAMpB,EAAE,QAAQ;;;;;;;;AAQV,CAAC;QAEG,MAAM,sBAAsB,SACzB,GAAG,CAAC,CAAC,MAAQ,GAAG,IAAI,IAAI,CAAC,EAAE,EAAE,IAAI,OAAO,EAAE,EAC1C,IAAI,CAAC;QAER,MAAM,aAAa,GAAG,OAAO,mBAAmB,EAAE,oBAAoB,cAAc,CAAC;QAErF,MAAM,WAAW,MAAM,MAAM,MAAM,CAAC,qBAAqB,CAAC;YACxD,OAAO;YACP,UAAU;QACZ;QAEA,MAAM,mHAAE,CAAC,MAAM,CAAC,0HAAS,EAAE,MAAM,CAAC;YAChC;YACA,SAAS,YAAY,OAAO;YAC5B,MAAM;QACR;QAEA,IAAI,WAAW;QAEf,wDAAwD;QACxD,MAAM,SAAS,IAAI,eAAe;YAChC,MAAM,OAAM,UAAU;gBACpB,MAAM,UAAU,IAAI;gBACpB,IAAI;oBACF,WAAW,MAAM,SAAS,SAAU;wBAClC,MAAM,OAAO,MAAM,IAAI;wBACvB,IAAI,MAAM;4BACR,YAAY;4BACZ,kEAAkE;4BAClE,MAAM,YAAY,CAAC,EAAE,EAAE,KAAK,SAAS,CAAC,MAAM,EAAE,CAAC;4BAC/C,WAAW,OAAO,CAAC,QAAQ,MAAM,CAAC;wBACpC;oBACF;gBACF,EAAE,OAAO,KAAK;oBACZ,QAAQ,KAAK,CAAC,iBAAiB;oBAC/B,WAAW,KAAK,CAAC;gBACnB,SAAU;oBACR,yCAAyC;oBACzC,IAAI,UAAU;wBACZ,MAAM,mHAAE,CAAC,MAAM,CAAC,0HAAS,EAAE,MAAM,CAAC;4BAChC;4BACA,SAAS;4BACT,MAAM;wBACR;oBACF;oBACA,WAAW,KAAK;gBAClB;YACF;QACF;QAEA,kDAAkD;QAClD,OAAO,IAAI,SAAS,QAAQ;YAC1B,SAAS;gBACP,gBAAgB;gBAChB,2BAA2B;YAC7B;QACF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,GAAG,CAAC;QACZ,OAAO,+PAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAA+B,GACxC;YAAE,QAAQ;QAAI;IAElB;AACF;AAEA,eAAe,mBAAmB,MAAc,EAAE,OAAiB;IACjE,MAAM,SAAS,MAAM,mHAAE,CAAC,MAAM,GAAG,IAAI,CAAC,uHAAK,EAAE,KAAK,CAAC,IAAA,mRAAE,EAAC,uHAAK,CAAC,EAAE,EAAE;IAChE,IAAI,OAAO,MAAM,KAAK,GAAG;IACzB,OAAO,MAAM,CAAC,EAAE,CAAC,OAAO;AAC1B","debugId":null}}]
}